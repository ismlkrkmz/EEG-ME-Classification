"""
Real-time Performance Analyzer for EEG-based BCI Systems
========================================================

This script analyzes the performance metrics generated by the EEG experiment
to assess the feasibility of real-time BCI implementation.

Author: Ismail Korkmaz
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def load_performance_data(results_dir='./results'):
    """
    Load performance metrics from all experiment results.
    
    Parameters:
    -----------
    results_dir : str
        Directory containing experiment results
    
    Returns:
    --------
    combined_data : dict
        Dictionary containing combined performance data for all methods
    """
    results_path = Path(results_dir)
    combined_data = {}
    
    # Find all result directories
    method_dirs = [d for d in results_path.iterdir() if d.is_dir()]
    
    for method_dir in method_dirs:
        method_name = method_dir.name
        perf_file = method_dir / 'performance_metrics.csv'
        summary_file = method_dir / 'summary_statistics.csv'
        
        if perf_file.exists() and summary_file.exists():
            # Load performance metrics
            perf_df = pd.read_csv(perf_file, index_col=0)
            summary_df = pd.read_csv(summary_file, index_col=0)
            
            combined_data[method_name] = {
                'performance_metrics': perf_df,
                'summary_statistics': summary_df
            }
            print(f"Loaded data for {method_name}")
    
    return combined_data


def analyze_real_time_feasibility(combined_data):
    """
    Analyze real-time feasibility across all methods.
    
    Parameters:
    -----------
    combined_data : dict
        Combined performance data
    
    Returns:
    --------
    feasibility_summary : pd.DataFrame
        Summary of real-time feasibility metrics
    """
    feasibility_data = []
    
    for method_name, data in combined_data.items():
        summary = data['summary_statistics']
        
        # Extract key metrics
        avg_time = summary.loc['avg_prediction_time_ms', 'Value']
        avg_memory = summary.loc['avg_memory_mb', 'Value']
        avg_size = summary.loc['avg_model_size_kb', 'Value']
        feasible_pct = summary.loc['real_time_feasible_percentage', 'Value']
        
        # Parse method name
        parts = method_name.split('_')
        feature_method = parts[0]
        classifier = parts[1] if len(parts) > 1 else 'unknown'
        
        feasibility_data.append({
            'Method': method_name,
            'Feature': feature_method.upper(),
            'Classifier': classifier.upper(),
            'Avg_Prediction_Time_ms': float(avg_time),
            'Avg_Memory_MB': float(avg_memory),
            'Avg_Model_Size_KB': float(avg_size),
            'Real_Time_Feasible_Pct': float(feasible_pct)
        })
    
    feasibility_df = pd.DataFrame(feasibility_data)
    
    # Sort by prediction time
    feasibility_df = feasibility_df.sort_values('Avg_Prediction_Time_ms')
    
    return feasibility_df


def create_performance_visualizations(combined_data, feasibility_summary):
    """
    Create comprehensive performance visualizations.
    
    Parameters:
    -----------
    combined_data : dict
        Combined performance data
    feasibility_summary : pd.DataFrame
        Summary of feasibility metrics
    """
    # Set up the plotting style
    plt.style.use('default')
    sns.set_palette("husl")
    
    # Create figure with subplots
    fig = plt.figure(figsize=(20, 15))
    
    # 1. Prediction time comparison
    ax1 = plt.subplot(2, 3, 1)
    bars1 = ax1.bar(range(len(feasibility_summary)), 
                    feasibility_summary['Avg_Prediction_Time_ms'],
                    color=['green' if x > 70 else 'orange' if x > 30 else 'red' 
                           for x in feasibility_summary['Real_Time_Feasible_Pct']])
    ax1.axhline(y=100, color='red', linestyle='--', alpha=0.7, label='Real-time threshold (100ms)')
    ax1.set_xlabel('Method')
    ax1.set_ylabel('Prediction Time (ms)')
    ax1.set_title('Average Prediction Time by Method')
    ax1.set_xticks(range(len(feasibility_summary)))
    ax1.set_xticklabels(feasibility_summary['Method'], rotation=45, ha='right')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for i, v in enumerate(feasibility_summary['Avg_Prediction_Time_ms']):
        ax1.text(i, v + 1, f'{v:.1f}', ha='center', va='bottom', fontsize=8)
    
    # 2. Memory usage comparison
    ax2 = plt.subplot(2, 3, 2)
    bars2 = ax2.bar(range(len(feasibility_summary)), 
                    feasibility_summary['Avg_Memory_MB'],
                    color='skyblue')
    ax2.set_xlabel('Method')
    ax2.set_ylabel('Memory Usage (MB)')
    ax2.set_title('Average Memory Usage by Method')
    ax2.set_xticks(range(len(feasibility_summary)))
    ax2.set_xticklabels(feasibility_summary['Method'], rotation=45, ha='right')
    ax2.grid(True, alpha=0.3)
    
    # 3. Model size comparison
    ax3 = plt.subplot(2, 3, 3)
    bars3 = ax3.bar(range(len(feasibility_summary)), 
                    feasibility_summary['Avg_Model_Size_KB'],
                    color='lightcoral')
    ax3.set_xlabel('Method')
    ax3.set_ylabel('Model Size (KB)')
    ax3.set_title('Average Model Size by Method')
    ax3.set_xticks(range(len(feasibility_summary)))
    ax3.set_xticklabels(feasibility_summary['Method'], rotation=45, ha='right')
    ax3.grid(True, alpha=0.3)
    
    # 4. Real-time feasibility percentage
    ax4 = plt.subplot(2, 3, 4)
    colors = ['green' if x > 70 else 'orange' if x > 30 else 'red' 
              for x in feasibility_summary['Real_Time_Feasible_Pct']]
    bars4 = ax4.bar(range(len(feasibility_summary)), 
                    feasibility_summary['Real_Time_Feasible_Pct'],
                    color=colors)
    ax4.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Good threshold (80%)')
    ax4.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable threshold (50%)')
    ax4.set_xlabel('Method')
    ax4.set_ylabel('Real-time Feasible (%)')
    ax4.set_title('Real-time Feasibility by Method')
    ax4.set_xticks(range(len(feasibility_summary)))
    ax4.set_xticklabels(feasibility_summary['Method'], rotation=45, ha='right')
    ax4.set_ylim(0, 100)
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # Add percentage labels
    for i, v in enumerate(feasibility_summary['Real_Time_Feasible_Pct']):
        ax4.text(i, v + 2, f'{v:.0f}%', ha='center', va='bottom', fontsize=8)
    
    # 5. Feature method comparison
    ax5 = plt.subplot(2, 3, 5)
    feature_groups = feasibility_summary.groupby('Feature').agg({
        'Avg_Prediction_Time_ms': 'mean',
        'Real_Time_Feasible_Pct': 'mean'
    })
    
    x_pos = np.arange(len(feature_groups))
    bars5_1 = ax5.bar(x_pos - 0.2, feature_groups['Avg_Prediction_Time_ms'], 
                      0.4, label='Avg Prediction Time (ms)', alpha=0.8)
    
    ax5_twin = ax5.twinx()
    bars5_2 = ax5_twin.bar(x_pos + 0.2, feature_groups['Real_Time_Feasible_Pct'], 
                           0.4, label='Feasible %', alpha=0.8, color='orange')
    
    ax5.set_xlabel('Feature Extraction Method')
    ax5.set_ylabel('Prediction Time (ms)')
    ax5_twin.set_ylabel('Real-time Feasible (%)')
    ax5.set_title('Performance by Feature Extraction Method')
    ax5.set_xticks(x_pos)
    ax5.set_xticklabels(feature_groups.index)
    
    # Combined legend
    lines1, labels1 = ax5.get_legend_handles_labels()
    lines2, labels2 = ax5_twin.get_legend_handles_labels()
    ax5.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
    
    # 6. Classifier comparison
    ax6 = plt.subplot(2, 3, 6)
    classifier_groups = feasibility_summary.groupby('Classifier').agg({
        'Avg_Prediction_Time_ms': 'mean',
        'Real_Time_Feasible_Pct': 'mean'
    })
    
    x_pos = np.arange(len(classifier_groups))
    bars6_1 = ax6.bar(x_pos - 0.2, classifier_groups['Avg_Prediction_Time_ms'], 
                      0.4, label='Avg Prediction Time (ms)', alpha=0.8)
    
    ax6_twin = ax6.twinx()
    bars6_2 = ax6_twin.bar(x_pos + 0.2, classifier_groups['Real_Time_Feasible_Pct'], 
                           0.4, label='Feasible %', alpha=0.8, color='orange')
    
    ax6.set_xlabel('Classifier')
    ax6.set_ylabel('Prediction Time (ms)')
    ax6_twin.set_ylabel('Real-time Feasible (%)')
    ax6.set_title('Performance by Classifier')
    ax6.set_xticks(x_pos)
    ax6.set_xticklabels(classifier_groups.index)
    
    # Combined legend
    lines1, labels1 = ax6.get_legend_handles_labels()
    lines2, labels2 = ax6_twin.get_legend_handles_labels()
    ax6.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
    
    plt.tight_layout()
    plt.savefig('./results/real_time_performance_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()


def generate_bci_recommendations(feasibility_summary):
    """
    Generate recommendations for real-time BCI implementation.
    
    Parameters:
    -----------
    feasibility_summary : pd.DataFrame
        Summary of feasibility metrics
    
    Returns:
    --------
    recommendations : dict
        Dictionary containing recommendations
    """
    recommendations = {}
    
    # Find best performing methods
    # Sort by feasibility percentage first, then by prediction time
    sorted_methods = feasibility_summary.sort_values(
        ['Real_Time_Feasible_Pct', 'Avg_Prediction_Time_ms'], 
        ascending=[False, True]
    )
    
    # Top 3 methods for real-time BCI
    top_methods = sorted_methods.head(3)
    
    recommendations['best_methods'] = []
    for _, method in top_methods.iterrows():
        recommendations['best_methods'].append({
            'method': method['Method'],
            'prediction_time_ms': method['Avg_Prediction_Time_ms'],
            'feasible_percentage': method['Real_Time_Feasible_Pct'],
            'memory_mb': method['Avg_Memory_MB'],
            'model_size_kb': method['Avg_Model_Size_KB']
        })
    
    # Hardware requirements
    max_memory = feasibility_summary['Avg_Memory_MB'].max()
    max_model_size = feasibility_summary['Avg_Model_Size_KB'].max()
    min_prediction_time = feasibility_summary['Avg_Prediction_Time_ms'].min()
    
    recommendations['hardware_requirements'] = {
        'minimum_ram_mb': max_memory * 2,  # 2x for safety margin
        'storage_mb': max_model_size / 1024 * 10,  # 10x for all models
        'cpu_requirement': 'Standard desktop CPU sufficient' if min_prediction_time < 50 else 'High-performance CPU recommended'
    }
    
    # Real-time implementation guidelines
    fast_methods = feasibility_summary[feasibility_summary['Avg_Prediction_Time_ms'] < 50]
    moderate_methods = feasibility_summary[
        (feasibility_summary['Avg_Prediction_Time_ms'] >= 50) & 
        (feasibility_summary['Avg_Prediction_Time_ms'] < 100)
    ]
    
    recommendations['implementation_guidelines'] = {
        'real_time_ready': len(fast_methods),
        'near_real_time': len(moderate_methods),
        'optimization_needed': len(feasibility_summary) - len(fast_methods) - len(moderate_methods),
        'recommended_sampling_rate': '250Hz or lower for best compatibility',
        'buffer_size_recommendation': '1-2 seconds for stable performance'
    }
    
    return recommendations


def main():
    """Main function to run the performance analysis."""
    print("EEG BCI Real-time Performance Analyzer")
    print("=" * 50)
    
    # Load performance data
    print("Loading performance data...")
    combined_data = load_performance_data()
    
    if not combined_data:
        print("No performance data found. Please run the experiment first.")
        return
    
    # Analyze feasibility
    print("Analyzing real-time feasibility...")
    feasibility_summary = analyze_real_time_feasibility(combined_data)
    
    # Display summary table
    print("\nReal-time Performance Summary:")
    print("-" * 80)
    print(feasibility_summary.to_string(index=False, float_format='%.2f'))
    
    # Create visualizations
    print("\nGenerating performance visualizations...")
    create_performance_visualizations(combined_data, feasibility_summary)
    
    # Generate recommendations
    print("\nGenerating BCI implementation recommendations...")
    recommendations = generate_bci_recommendations(feasibility_summary)
    
    # Display recommendations
    print("\nBCI Implementation Recommendations:")
    print("=" * 50)
    
    print("\nTop 3 Methods for Real-time BCI:")
    for i, method in enumerate(recommendations['best_methods'], 1):
        print(f"{i}. {method['method']}:")
        print(f"   - Prediction time: {method['prediction_time_ms']:.2f} ms")
        print(f"   - Real-time feasible: {method['feasible_percentage']:.1f}% of subjects")
        print(f"   - Memory usage: {method['memory_mb']:.1f} MB")
        print(f"   - Model size: {method['model_size_kb']:.1f} KB")
    
    print(f"\nHardware Requirements:")
    hw = recommendations['hardware_requirements']
    print(f"   - Minimum RAM: {hw['minimum_ram_mb']:.0f} MB")
    print(f"   - Storage: {hw['storage_mb']:.1f} MB")
    print(f"   - CPU: {hw['cpu_requirement']}")
    
    print(f"\nImplementation Guidelines:")
    ig = recommendations['implementation_guidelines']
    print(f"   - Real-time ready methods: {ig['real_time_ready']}")
    print(f"   - Near real-time methods: {ig['near_real_time']}")
    print(f"   - Methods needing optimization: {ig['optimization_needed']}")
    print(f"   - Recommended sampling rate: {ig['recommended_sampling_rate']}")
    print(f"   - Buffer size recommendation: {ig['buffer_size_recommendation']}")
    
    # Save detailed results
    feasibility_summary.to_csv('./results/real_time_feasibility_summary.csv', index=False)
    
    import json
    with open('./results/bci_recommendations.json', 'w') as f:
        json.dump(recommendations, f, indent=2)
    
    print(f"\nDetailed results saved to:")
    print(f"   - ./results/real_time_feasibility_summary.csv")
    print(f"   - ./results/bci_recommendations.json")
    print(f"   - ./results/real_time_performance_analysis.png")


if __name__ == "__main__":
    main() 